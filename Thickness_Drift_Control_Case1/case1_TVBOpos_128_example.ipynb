{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the font \"Times\" is not available, so \"Lucida Bright\" has been substituted, but may have unexpected appearance or behavor. Re-enable the \"Times\" font to remove this warning.\n",
      "Warning: the font \"Times\" is not available, so \"Lucida Bright\" has been substituted, but may have unexpected appearance or behavor. Re-enable the \"Times\" font to remove this warning.\n"
     ]
    }
   ],
   "source": [
    "import botorch\n",
    "import torch\n",
    "import matlab.engine\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "eng = matlab.engine.start_matlab()\n",
    "eng.cd(r'./MPC_BO_Thickness_ver7.0_CASE1', nargout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the second return is 1 if succeed, 0 otherwise\n",
    "def problem_wrapper(dA=1.5):\n",
    "    def problem(Tref, Iref, Aref1, Aref2, Aref3):\n",
    "        res = eng.RT_control_return(Tref, Iref, matlab.double([[Aref1],[Aref2],[Aref3]]), dA, stdout=io.StringIO())\n",
    "        return torch.from_numpy(np.asarray(res))\n",
    "    return problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkwargs = {\n",
    "    \"dtype\": torch.double,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models.gp_regression import FixedNoiseGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import normalize, unnormalize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement\n",
    "from botorch.acquisition.objective import MCAcquisitionObjective\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "NUM_RESTARTS = 256 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
    "\n",
    "bounds = torch.tensor([[35, 1500, 1.4016/2., -14.4395*2., 12.5570/2.],\n",
    "                       [65, 3000, 1.4016*2., -14.4395/2., 12.5570*2.]]).to(**tkwargs)\n",
    "#bounds = torch.tensor([[35, 1500, 1.4016*1.0, -14.4395*1.5, 12.5570*1.0],\n",
    "#                       [65, 3000, 1.4016*1.5, -14.4395*1.0, 12.5570*1.5]]).to(**tkwargs)\n",
    "standard_bounds = torch.zeros(2, bounds.shape[1], **tkwargs)\n",
    "standard_bounds[1] = 1\n",
    "# need to also include the bounds for the run idx\n",
    "# though this is fixed during AF optimization\n",
    "bounds = torch.cat((bounds, torch.tensor([[0],[100]]).to(**tkwargs)), dim=-1)\n",
    "bounds[1, -1] = 1.\n",
    "# we do not normalized the time (index)\n",
    "standard_bounds = torch.cat((standard_bounds, torch.tensor([[0],[100]]).to(**tkwargs)), dim=-1)\n",
    "# extra bounds for time (index) to make the AF optimization happy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_kernels import PosEncode\n",
    "from covar_module import get_spatio_temp_kernel\n",
    "NOISE_SE = torch.tensor([0.0] * 1, **tkwargs)\n",
    "\n",
    "def generate_initial_data(problem, n=7, guaratee_feasible=True):\n",
    "    # generate training data\n",
    "    train_x = draw_sobol_samples(bounds=bounds[:,:-1], n=n, q=1).squeeze(1)\n",
    "    train_obj_plain = torch.cat([problem(*_.tolist()).reshape(1,-1) for _ in train_x], dim=0)\n",
    "    train_obj_true = train_obj_plain[..., :-1]\n",
    "    train_obj = train_obj_true + torch.randn_like(train_obj_true) * NOISE_SE\n",
    "    if guaratee_feasible:\n",
    "        final_train_x = torch.zeros((0, train_x.shape[-1]))\n",
    "        final_train_obj_true = torch.zeros((0, train_obj_true.shape[-1]))\n",
    "        final_train_obj = torch.zeros_like(final_train_obj_true)\n",
    "        mask = (train_obj_plain[:, -1] == 1).reshape(-1)\n",
    "        final_train_x = torch.cat((final_train_x, train_x[mask, :]), dim=0)\n",
    "        final_train_obj_true = torch.cat((final_train_obj_true, train_obj_true[mask, :]), dim=0)\n",
    "        final_train_obj = torch.cat((final_train_obj, train_obj[mask, :]), dim=0)\n",
    "        n = n-final_train_x.shape[0]\n",
    "        while n:\n",
    "            train_x = draw_sobol_samples(bounds=bounds[:,:-1], n=n, q=1).squeeze(1)\n",
    "            train_obj_plain = torch.cat([problem(*_.tolist()).reshape(1,-1) for _ in train_x], dim=0)\n",
    "            train_obj_true = train_obj_plain[..., :-1]\n",
    "            train_obj = train_obj_true + torch.randn_like(train_obj_true) * NOISE_SE\n",
    "            mask = (train_obj_plain[:, -1] == 1).reshape(-1)\n",
    "            final_train_x = torch.cat((final_train_x, train_x[mask, :]), dim=0)\n",
    "            final_train_obj_true = torch.cat((final_train_obj_true, train_obj_true[mask, :]), dim=0)\n",
    "            final_train_obj = torch.cat((final_train_obj, train_obj[mask, :]), dim=0)\n",
    "            n = n-train_x[mask, :].shape[0]\n",
    "        return final_train_x, final_train_obj, final_train_obj_true\n",
    "\n",
    "    return train_x, train_obj, train_obj_true\n",
    "\n",
    "\n",
    "def initialize_model(train_x, \n",
    "                     train_obj, \n",
    "                     input_trans=None, \n",
    "                     input_trans_args=None,\n",
    "                     type_of_forgetting='UI',\n",
    "                     forgetting_factor=0.03):\n",
    "    # define models for objective and constraint\n",
    "    train_x = normalize(train_x, bounds)\n",
    "    models = []\n",
    "    for i in range(train_obj.shape[-1]):\n",
    "        train_y = train_obj[..., i : i + 1]\n",
    "        train_yvar = torch.full_like(train_y, NOISE_SE[i] ** 2)\n",
    "        covar = get_spatio_temp_kernel(train_x,\n",
    "                                       train_y, \n",
    "                                       type_of_forgetting=type_of_forgetting,\n",
    "                                       forgetting_factor=forgetting_factor)\n",
    "        if input_trans is not None:\n",
    "            models.append(FixedNoiseGP(train_x,\n",
    "                                       train_y, \n",
    "                                       train_yvar, \n",
    "                                       covar_module=covar,\n",
    "                                       outcome_transform=Standardize(m=1), \n",
    "                                       input_transform=input_trans(**input_trans_args)))\n",
    "        else:         \n",
    "            models.append(FixedNoiseGP(train_x, \n",
    "                                       train_y, \n",
    "                                       train_yvar,\n",
    "                                       covar_module=covar, \n",
    "                                       outcome_transform=Standardize(m=1)))\n",
    "    model = models[0] # in this case it is single objective!!!\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    return mll, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a MCMultiOutputObjective convert thickness and time to\n",
    "# (thickness-ref_thickness)**2 and (time-ref_time)**2\n",
    "\n",
    "class obj_convert(MCAcquisitionObjective):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, samples, X = None):\n",
    "        ans = -(samples-1.)**2\n",
    "        if ans.shape[-1] == 1:\n",
    "            ans = ans.squeeze(-1)\n",
    "        return ans # just the thickness\n",
    "\n",
    "\n",
    "def optimize_qnehvi_and_get_observation(model, train_x, train_obj, sampler, problem, run_num):\n",
    "    \"\"\"Optimizes the qEHVI acquisition function, and returns a new candidate and observation.\"\"\"\n",
    "    batch = BATCH_SIZE\n",
    "    # build the casadi optimization for MPC retry here\n",
    "    final_new_x = torch.zeros((0, train_x.shape[-1])).to(train_x)\n",
    "    final_new_obj = torch.zeros((0, train_obj.shape[-1])).to(train_obj)\n",
    "    final_new_obj_true = torch.zeros((0, train_obj.shape[-1])).to(train_obj)\n",
    "\n",
    "    # check how many recalculation we did....\n",
    "    retry_count = 0\n",
    "    while batch and retry_count <= BATCH_SIZE*100:\n",
    "        retry_count += batch\n",
    "        # partition non-dominated space into disjoint rectangles\n",
    "        acq_func = qNoisyExpectedImprovement(\n",
    "            model=model,\n",
    "            objective=obj_convert(),\n",
    "            X_baseline=normalize(train_x, bounds),\n",
    "            prune_baseline=True,  # prune baseline points that have estimated zero probability of being Pareto optimal\n",
    "            sampler=sampler,\n",
    "        )\n",
    "        # optimize\n",
    "        candidates, _ = optimize_acqf(\n",
    "            acq_function=acq_func,\n",
    "            bounds=standard_bounds,\n",
    "            fixed_features={bounds.shape[-1]-1: float(run_num)},\n",
    "            q=batch,\n",
    "            num_restarts=NUM_RESTARTS,\n",
    "            raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "            options={\"batch_limit\": 5, \"maxiter\": 1000},\n",
    "            sequential=True,\n",
    "        )\n",
    "        # observe new values\n",
    "        new_x = unnormalize(candidates[...,:-1].detach(), bounds=bounds[:,:-1])\n",
    "        new_obj_true = torch.cat([problem(*_.tolist()).reshape(1,-1) for _ in new_x], dim=0)\n",
    "        #print(new_obj_true)\n",
    "        # check solution status\n",
    "        succeed = new_obj_true[:, -1] == 1.\n",
    "        #print(succeed)\n",
    "        new_x = new_x[succeed.reshape(-1), :]\n",
    "        #print(new_x.shape)\n",
    "        candidates = candidates[succeed.reshape(-1), :]\n",
    "        # chop donw the final dimension, which is just the MPC optimization succeed status\n",
    "        new_obj_true = new_obj_true[succeed.reshape(-1), :-1]\n",
    "        new_obj = new_obj_true + torch.randn_like(new_obj_true) * NOISE_SE\n",
    "        new_x = torch.cat((new_x, candidates[...,-1].detach().unsqueeze(-1)), dim=-1)\n",
    "\n",
    "        final_new_x = torch.cat([final_new_x, new_x], dim=0)\n",
    "        final_new_obj = torch.cat([final_new_obj, new_obj], dim=0)\n",
    "        final_new_obj_true = torch.cat([final_new_obj_true, new_obj_true], dim=0)\n",
    "\n",
    "        # check if we need more calculation...\n",
    "        batch = batch - new_x.shape[0]\n",
    "\n",
    "    return final_new_x, final_new_obj, final_new_obj_true, retry_count <= BATCH_SIZE*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "with open('../data_init.pkl', 'rb') as fp:\n",
    "    old_res = pickle.load(fp)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_init(n=5):\n",
    "    cur_problem = problem_wrapper(1.0)\n",
    "    #train_init = generate_initial_data(cur_problem, n=n)\n",
    "    train_init = (old_res['outcome_X'][:10,:-1], old_res['outcome_Y'][:10,:], old_res['outcome_Y'][:10,:])\n",
    "    def BO_wrapper_with_same_init(embed_dim,\n",
    "                                  reduce_to_one, \n",
    "                                  batch_num,\n",
    "                                  type_of_forgetting='UI',\n",
    "                                  forgetting_factor=0.03):\n",
    "        import time\n",
    "        import warnings\n",
    "\n",
    "        from botorch.exceptions import BadInitialCandidatesWarning\n",
    "        from botorch.fit import fit_gpytorch_model\n",
    "        from botorch.sampling import SobolQMCNormalSampler\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "        N_BATCH = batch_num if not SMOKE_TEST else 10        \n",
    "        MC_SAMPLES = 512 if not SMOKE_TEST else 16\n",
    "\n",
    "        verbose = True\n",
    "\n",
    "        while True:\n",
    "            restart_flag = False\n",
    "            # call helper functions to generate initial training data and initialize model\n",
    "            res = {}\n",
    "            train_x_qnehvi, train_obj_qnehvi, train_obj_true_qnehvi = train_init\n",
    "            # need to assign index of 0, indicating we have data of the un-drifted model\n",
    "            train_x_qnehvi = torch.cat((train_x_qnehvi, torch.zeros((train_x_qnehvi.shape[0], 1)).to(**tkwargs)), dim=-1)\n",
    "            if embed_dim is not None:\n",
    "                mll_qnehvi, model_qnehvi = initialize_model(train_x_qnehvi, train_obj_qnehvi, \n",
    "                                                            PosEncode, {\"positional_emb_dim\": embed_dim, \"reduce_to_one\": reduce_to_one, \"tkwargs\": tkwargs},\n",
    "                                                            type_of_forgetting=type_of_forgetting, forgetting_factor=forgetting_factor)\n",
    "            else:\n",
    "                mll_qnehvi, model_qnehvi = initialize_model(train_x_qnehvi, train_obj_qnehvi,\n",
    "                                                            type_of_forgetting=type_of_forgetting, forgetting_factor=forgetting_factor)\n",
    "\n",
    "            # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "            for iteration in range(2, N_BATCH + 1):\n",
    "\n",
    "                t0 = time.monotonic()\n",
    "\n",
    "                # fit the models\n",
    "                #for name, _ in mll_qnehvi.named_parameters():\n",
    "                #    print(name, _)\n",
    "                fit_gpytorch_model(mll_qnehvi)\n",
    "                #for name, _ in mll_qnehvi.named_parameters():\n",
    "                #    print(name, _)\n",
    "\n",
    "                # define the qEI and qNEI acquisition modules using a QMC sampler\n",
    "                qnehvi_sampler = SobolQMCNormalSampler(MC_SAMPLES)\n",
    "                #if iteration > 20:\n",
    "                #    run_num = 20 - 1\n",
    "                #else:\n",
    "                #    run_num = iteration-1\n",
    "                #dA_init = 1.0\n",
    "                #dA_final = 1.5\n",
    "                #No_run_max = 20\n",
    "                #dA = dA_init - (dA_init - dA_final)/(No_run_max-1)*(run_num)\n",
    "                \n",
    "                run_num = iteration-1\n",
    "                dA = 0.5 /(1 + math.exp(-0.15*(run_num-50-1)))+1            \n",
    "                #dA = 0.5 /(1 + math.exp(-0.10*(run_num-50-1)))+1        \n",
    "                print('\\n', dA)\n",
    "                cur_problem = problem_wrapper(dA)\n",
    "\n",
    "                # optimize acquisition functions and get new observations\n",
    "                (\n",
    "                    new_x_qnehvi,\n",
    "                    new_obj_qnehvi,\n",
    "                    new_obj_true_qnehvi,\n",
    "                    exit_status,\n",
    "                ) = optimize_qnehvi_and_get_observation(model_qnehvi, train_x_qnehvi, train_obj_qnehvi, qnehvi_sampler, cur_problem, run_num)\n",
    "\n",
    "                # if we failed to optimize several times (currently BATCH_SIZE*100), we just dump this trajectory!\n",
    "                if not exit_status and new_x_qnehvi.shape[0] != BATCH_SIZE:\n",
    "                    restart_flag = True\n",
    "                    continue\n",
    "                # update training points\n",
    "                train_x_qnehvi = torch.cat([train_x_qnehvi, new_x_qnehvi])\n",
    "                train_obj_qnehvi = torch.cat([train_obj_qnehvi, new_obj_qnehvi])\n",
    "                train_obj_true_qnehvi = torch.cat([train_obj_true_qnehvi, new_obj_true_qnehvi])\n",
    "\n",
    "                # reinitialize the models so they are ready for fitting on next iteration\n",
    "                # Note: we find improved performance from not warm starting the model hyperparameters\n",
    "                # using the hyperparameters from the previous iteration\n",
    "                if embed_dim is not None:\n",
    "                    mll_qnehvi, model_qnehvi = initialize_model(train_x_qnehvi, train_obj_qnehvi, \n",
    "                                                                PosEncode, {\"positional_emb_dim\": embed_dim, \"reduce_to_one\": reduce_to_one, \"tkwargs\": tkwargs},\n",
    "                                                                type_of_forgetting=type_of_forgetting, forgetting_factor=forgetting_factor)\n",
    "                else:\n",
    "                    mll_qnehvi, model_qnehvi = initialize_model(train_x_qnehvi, train_obj_qnehvi,\n",
    "                                                                type_of_forgetting=type_of_forgetting, forgetting_factor=forgetting_factor)\n",
    "\n",
    "                t1 = time.monotonic()\n",
    "\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"\\nBatch {iteration:>2}: \"\n",
    "                        f\"time = {t1-t0:>4.2f}\",\n",
    "                        end=\"\",\n",
    "                    )\n",
    "                else:\n",
    "                    print(\".\", end=\"\")\n",
    "            if restart_flag:\n",
    "                continue\n",
    "            res[\"outcome_X\"] = train_x_qnehvi\n",
    "            res[\"outcome_Y\"] = train_obj_qnehvi\n",
    "            return res\n",
    "    return BO_wrapper_with_same_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_drift = same_init(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plain_res = []\n",
    "#for _ in range(5):\n",
    "    # plain_res.append(run_drift(None, False, 100, None, 0.03)) # BO\n",
    "    # plain_res.append(run_drift(None, False, 100, 'UI_learning', 0.03)) # TVBO\n",
    "\n",
    "pos_emb_res = []\n",
    "for _ in range(5):\n",
    "    pos_emb_res.append(run_drift(128, True, 100, 'UI_learning', 0.03)) # TVBO Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
